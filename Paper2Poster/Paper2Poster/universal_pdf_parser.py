#!/usr/bin/env python3
"""
é€šç”¨PDFè§£æå™¨ - æ”¯æŒå¤šç§æ–‡æ¡£ç±»å‹
åŒ…æ‹¬å­¦æœ¯è®ºæ–‡ã€æŠ€æœ¯æŠ¥å‘Šã€å•†ä¸šæ–‡æ¡£ã€è¯´æ˜ä¹¦ç­‰
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from enum import Enum

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from parser_agent_openrouter import OpenRouterParserAgent

class DocumentType(Enum):
    """æ–‡æ¡£ç±»å‹æšä¸¾"""
    ACADEMIC_PAPER = "academic_paper"
    TECHNICAL_REPORT = "technical_report"
    BUSINESS_DOCUMENT = "business_document"
    MANUAL = "manual"
    NEWS_ARTICLE = "news_article"
    BOOK_CHAPTER = "book_chapter"
    GENERAL = "general"

class UniversalPDFParser(OpenRouterParserAgent):
    """é€šç”¨PDFè§£æå™¨ï¼Œæ”¯æŒå¤šç§æ–‡æ¡£ç±»å‹"""
    
    def __init__(self, model_name: str = "gpt-4o", document_type: DocumentType = DocumentType.GENERAL):
        """
        åˆå§‹åŒ–é€šç”¨è§£æå™¨
        
        Args:
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
            document_type: æ–‡æ¡£ç±»å‹
        """
        self.document_type = document_type
        super().__init__(model_name)
    
    def _get_prompt_template(self) -> str:
        """æ ¹æ®æ–‡æ¡£ç±»å‹è·å–ç›¸åº”çš„æç¤ºæ¨¡æ¿"""
        
        base_instructions = """You are a document content divider and extractor specialist, expert in dividing and extracting content from various types of documents and reorganizing it into a structured JSON format.

Based on the given markdown document, generate a JSON output that captures the key information and structure of the document.

Step-by-Step Instructions:
1. Identify the main sections and logical structure of the document
2. Divide content into meaningful sections with approximately 300-800 words each
3. Create concise titles for each section (2-4 words)
4. Remove unwanted elements like headers, footers, page numbers, and irrelevant annotations
5. Preserve important formatting and structure information
6. Extract relevant metadata based on document type

"""
        
        # æ ¹æ®æ–‡æ¡£ç±»å‹å®šåˆ¶æŒ‡ä»¤å’Œæ ¼å¼
        if self.document_type == DocumentType.ACADEMIC_PAPER:
            specific_instructions = """
7. Focus on: Abstract, Introduction, Methodology, Results, Conclusion
8. Extract: title, authors, affiliations, keywords
9. Maintain academic structure and terminology

Example Output:
{
    "meta": {
        "title": "Document title",
        "authors": "Author names",
        "affiliations": "Institution information",
        "document_type": "academic_paper"
    },
    "sections": [
        {"title": "Abstract", "content": "..."},
        {"title": "Introduction", "content": "..."}
    ]
}"""
            
        elif self.document_type == DocumentType.TECHNICAL_REPORT:
            specific_instructions = """
7. Focus on: Executive Summary, Technical Details, Implementation, Recommendations
8. Extract: title, organization, report date, version
9. Emphasize technical specifications and procedures

Example Output:
{
    "meta": {
        "title": "Report title",
        "organization": "Publishing organization",
        "date": "Publication date",
        "document_type": "technical_report"
    },
    "sections": [
        {"title": "Executive Summary", "content": "..."},
        {"title": "Technical Details", "content": "..."}
    ]
}"""
            
        elif self.document_type == DocumentType.BUSINESS_DOCUMENT:
            specific_instructions = """
7. Focus on: Executive Summary, Business Objectives, Analysis, Recommendations
8. Extract: title, company, department, date
9. Highlight business metrics and strategic information

Example Output:
{
    "meta": {
        "title": "Document title",
        "company": "Company name",
        "department": "Department/Division",
        "document_type": "business_document"
    },
    "sections": [
        {"title": "Executive Summary", "content": "..."},
        {"title": "Business Analysis", "content": "..."}
    ]
}"""
            
        elif self.document_type == DocumentType.MANUAL:
            specific_instructions = """
7. Focus on: Overview, Setup/Installation, Usage Instructions, Troubleshooting
8. Extract: title, product/service name, version, publisher
9. Maintain step-by-step procedures and safety information

Example Output:
{
    "meta": {
        "title": "Manual title",
        "product": "Product/Service name",
        "version": "Version information",
        "document_type": "manual"
    },
    "sections": [
        {"title": "Overview", "content": "..."},
        {"title": "Setup Guide", "content": "..."}
    ]
}"""
            
        elif self.document_type == DocumentType.NEWS_ARTICLE:
            specific_instructions = """
7. Focus on: Headline, Lead, Body paragraphs, Conclusion
8. Extract: title, author, publication, date
9. Maintain journalistic structure and key facts

Example Output:
{
    "meta": {
        "title": "Article headline",
        "author": "Journalist name",
        "publication": "News outlet",
        "document_type": "news_article"
    },
    "sections": [
        {"title": "Lead Story", "content": "..."},
        {"title": "Details", "content": "..."}
    ]
}"""
            
        elif self.document_type == DocumentType.BOOK_CHAPTER:
            specific_instructions = """
7. Focus on: Chapter introduction, main concepts, examples, summary
8. Extract: chapter title, book title, author, chapter number
9. Preserve narrative flow and conceptual structure

Example Output:
{
    "meta": {
        "title": "Chapter title",
        "book_title": "Book title",
        "author": "Author name",
        "document_type": "book_chapter"
    },
    "sections": [
        {"title": "Introduction", "content": "..."},
        {"title": "Main Concepts", "content": "..."}
    ]
}"""
            
        else:  # GENERAL
            specific_instructions = """
7. Adapt to the document's natural structure and purpose
8. Extract: title and any relevant metadata available
9. Create logical sections based on content flow

Example Output:
{
    "meta": {
        "title": "Document title",
        "document_type": "general",
        "subject": "Main topic/theme"
    },
    "sections": [
        {"title": "Introduction", "content": "..."},
        {"title": "Main Content", "content": "..."}
    ]
}"""
        
        return base_instructions + specific_instructions + "\n\nGive your output in JSON format\nInput:\n{{ markdown_document }}\nOutput:"
    
    def _validate_and_optimize_content(self, content_json: Dict) -> Dict:
        """éªŒè¯å’Œä¼˜åŒ–å†…å®¹ - é€šç”¨ç‰ˆæœ¬"""
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if 'sections' not in content_json:
            raise ValueError("Missing 'sections' field in response")
        
        # éªŒè¯æ¯ä¸ªsectionçš„æ ¼å¼
        for section in content_json['sections']:
            if not isinstance(section, dict) or 'title' not in section or 'content' not in section:
                raise ValueError("Invalid section format")
        
        # ç¡®ä¿æœ‰metaä¿¡æ¯
        if 'meta' not in content_json:
            content_json['meta'] = {"document_type": self.document_type.value}
        else:
            content_json['meta']['document_type'] = self.document_type.value
        
        # å¦‚æœsectionè¿‡å¤šï¼Œè¿›è¡Œæ™ºèƒ½é€‰æ‹©
        if len(content_json['sections']) > 12:
            print(f"Sectionæ•°é‡è¿‡å¤š({len(content_json['sections'])}ä¸ª)ï¼Œè¿›è¡Œæ™ºèƒ½é€‰æ‹©...")
            # ä¿ç•™å¼€å¤´2ä¸ªï¼Œä¸­é—´éšæœºé€‰æ‹©8ä¸ªï¼Œç»“å°¾2ä¸ª
            import random
            selected_sections = (
                content_json['sections'][:2] + 
                random.sample(content_json['sections'][2:-2], min(8, len(content_json['sections'])-4)) + 
                content_json['sections'][-2:]
            )
            content_json['sections'] = selected_sections
            print(f"é€‰æ‹©åå‰©ä½™{len(content_json['sections'])}ä¸ªsections")
        
        return content_json

def auto_detect_document_type(pdf_path: str) -> DocumentType:
    """è‡ªåŠ¨æ£€æµ‹æ–‡æ¡£ç±»å‹ï¼ˆç®€å•å¯å‘å¼æ–¹æ³•ï¼‰"""
    filename = os.path.basename(pdf_path).lower()
    
    # åŸºäºæ–‡ä»¶åçš„å¯å‘å¼åˆ¤æ–­
    if any(keyword in filename for keyword in ['paper', 'journal', 'conference', 'arxiv']):
        return DocumentType.ACADEMIC_PAPER
    elif any(keyword in filename for keyword in ['report', 'technical', 'spec', 'specification']):
        return DocumentType.TECHNICAL_REPORT
    elif any(keyword in filename for keyword in ['business', 'proposal', 'plan', 'strategy']):
        return DocumentType.BUSINESS_DOCUMENT
    elif any(keyword in filename for keyword in ['manual', 'guide', 'instruction', 'handbook']):
        return DocumentType.MANUAL
    elif any(keyword in filename for keyword in ['news', 'article', 'press']):
        return DocumentType.NEWS_ARTICLE
    elif any(keyword in filename for keyword in ['chapter', 'book']):
        return DocumentType.BOOK_CHAPTER
    else:
        return DocumentType.GENERAL

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é€šç”¨PDFè§£æå™¨ - æ”¯æŒå¤šç§æ–‡æ¡£ç±»å‹")
    parser.add_argument("pdf_path", help="PDFæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output_dir", default="universal_output", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--model", default="gpt-4o-mini", help="ä½¿ç”¨çš„æ¨¡å‹åç§°")
    parser.add_argument("--doc_type", 
                        choices=[dt.value for dt in DocumentType],
                        help="æ–‡æ¡£ç±»å‹ (å¦‚æœä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ£€æµ‹)")
    parser.add_argument("--auto_detect", action="store_true", help="è‡ªåŠ¨æ£€æµ‹æ–‡æ¡£ç±»å‹")
    parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.pdf_path):
        print(f"é”™è¯¯: PDFæ–‡ä»¶ä¸å­˜åœ¨: {args.pdf_path}")
        return
    
    # ç¡®å®šæ–‡æ¡£ç±»å‹
    if args.doc_type:
        doc_type = DocumentType(args.doc_type)
        print(f"ğŸ“‹ ä½¿ç”¨æŒ‡å®šæ–‡æ¡£ç±»å‹: {doc_type.value}")
    elif args.auto_detect:
        doc_type = auto_detect_document_type(args.pdf_path)
        print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹æ–‡æ¡£ç±»å‹: {doc_type.value}")
    else:
        doc_type = DocumentType.GENERAL
        print(f"ğŸ“„ ä½¿ç”¨é€šç”¨æ–‡æ¡£ç±»å‹: {doc_type.value}")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        return
    
    try:
        # åˆ›å»ºé€šç”¨è§£æå™¨
        print(f"åˆå§‹åŒ–é€šç”¨è§£æå™¨ï¼Œä½¿ç”¨æ¨¡å‹: {args.model}")
        universal_parser = UniversalPDFParser(model_name=args.model, document_type=doc_type)
        
        # æ‰§è¡Œè§£æ
        content_json, images, tables = universal_parser.parse_raw(args.pdf_path, args.output_dir)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = universal_parser.get_parsing_stats(content_json, images, tables)
        
        # è¾“å‡ºç»“æœ
        print("\n" + "="*50)
        print("è§£æå®Œæˆï¼")
        print("="*50)
        
        print(f"ğŸ“„ è§£æç»Ÿè®¡:")
        print(f"  - æ–‡æ¡£ç±»å‹: {doc_type.value}")
        print(f"  - ä½¿ç”¨æ¨¡å‹: {stats['model_used']}")
        print(f"  - Sectionsæ•°é‡: {stats['sections_count']}")
        print(f"  - æ€»æ–‡æœ¬é•¿åº¦: {stats['total_text_length']:,} å­—ç¬¦")
        print(f"  - å¹³å‡sectioné•¿åº¦: {stats['avg_section_length']:.0f} å­—ç¬¦")
        print(f"  - å›¾ç‰‡æ•°é‡: {stats['images_count']}")
        print(f"  - è¡¨æ ¼æ•°é‡: {stats['tables_count']}")
        
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  - ç»“æ„åŒ–å†…å®¹: {args.output_dir}/parsed_content.json")
        print(f"  - å›¾ç‰‡ä¿¡æ¯: {args.output_dir}/images.json")
        print(f"  - è¡¨æ ¼ä¿¡æ¯: {args.output_dir}/tables.json")
        print(f"  - æ±‡æ€»ä¿¡æ¯: {args.output_dir}/summary.json")
        
        if args.verbose and content_json.get("meta"):
            print(f"\nğŸ“ æ–‡æ¡£ä¿¡æ¯:")
            meta = content_json["meta"]
            for key, value in meta.items():
                if value:
                    print(f"  - {key}: {value}")
        
        print(f"\nâœ… è§£ææˆåŠŸå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        import traceback
        if args.verbose:
            traceback.print_exc()

if __name__ == "__main__":
    main() 