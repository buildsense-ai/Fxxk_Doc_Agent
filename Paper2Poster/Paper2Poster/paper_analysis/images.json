{
    "1": {
        "caption": "Figure 1: (1) Comparison of 4 prompting methods, (a) Standard , (b) Chain-of-thought ( CoT , Reason Only), (c) Act -only, and (d) ReAct (Reason+Act), solving a HotpotQA (Yang et al., 2018) question. (2) Comparison of (a) Act -only and (b) ReAct prompting to solve an AlfWorld (Shridhar et al., 2020b) game. In both domains, we omit in-context examples in the prompt, and only show task solving trajectories generated by the model (Act, Thought) and the environment (Obs).",
        "image_path": "paper_analysis\\picture-1.png",
        "width": 1951,
        "height": 1596,
        "figure_size": 3113796,
        "figure_aspect": 1.2224310776942355
    },
    "3": {
        "caption": "Figure 2: PaLM-540B prompting results with respect to number of CoT-SC samples used.",
        "image_path": "paper_analysis\\picture-3.png",
        "width": 508,
        "height": 501,
        "figure_size": 254508,
        "figure_aspect": 1.0139720558882235
    },
    "4": {
        "caption": "Figure 3: Scaling results for prompting and finetuning on HotPotQA with ReAct (ours) and baselines.",
        "image_path": "paper_analysis\\picture-4.png",
        "width": 1448,
        "height": 572,
        "figure_size": 828256,
        "figure_aspect": 2.5314685314685317
    },
    "5": {
        "caption": "Figure 4: Another example HotpotQA question, where the original label is outdated. Only ReAct is able to obtain the up-to-date answer thanks to real-world web interaction plus reasoning.",
        "image_path": "paper_analysis\\picture-5.png",
        "width": 1971,
        "height": 821,
        "figure_size": 1618191,
        "figure_aspect": 2.400730816077954
    },
    "6": {
        "caption": "Figure 5: A human-in-the-loop behavior correction example with ReAct in AlfWorld. (a) ReAct trajectory fails due to a hallucinating thought (Act 17). (b) By a human simply editing two thoughts (Act 17, 23), the ReAct trajectory produces desirable reasoning traces and actions and succeeds.",
        "image_path": "paper_analysis\\picture-6.png",
        "width": 1966,
        "height": 761,
        "figure_size": 1496126,
        "figure_aspect": 2.583442838370565
    },
    "8": {
        "caption": "Hotpot QA Prompts - Continued from previous page",
        "image_path": "paper_analysis\\picture-8.png",
        "width": 70,
        "height": 40,
        "figure_size": 2800,
        "figure_aspect": 1.75
    }
}