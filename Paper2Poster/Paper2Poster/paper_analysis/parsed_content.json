{
    "meta": {
        "poster_title": "REACT: Synergizing Reasoning and Acting in Language Models",
        "authors": "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao",
        "affiliations": "Department of Computer Science, Princeton University; Google Research, Brain team"
    },
    "sections": [
        {
            "title": "Poster Title & Author",
            "content": "REACT: Synergizing Reasoning and Acting in Language Models\nAuthors: Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao\nAffiliations: Department of Computer Science, Princeton University; Google Research, Brain team"
        },
        {
            "title": "Abstract",
            "content": "While large language models (LLMs) have demonstrated impressive performance across tasks in language understanding and interactive decision making, their abilities for reasoning and acting have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with and gather additional information from external sources. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines."
        },
        {
            "title": "Introduction",
            "content": "A unique feature of human intelligence is the ability to seamlessly combine task-oriented actions with verbal reasoning. This tight synergy between acting and reasoning allows humans to learn new tasks quickly and perform robust decision making. Recent results have hinted at the possibility of combining verbal reasoning with interactive decision making in autonomous systems. ReAct prompts LLMs to generate both verbal reasoning traces and actions pertaining to a task in an interleaved manner, allowing the model to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting."
        },
        {
            "title": "ReAct Methodology",
            "content": "The idea of ReAct is simple: we augment the agent's action space to include language, where a thought or reasoning trace aims to compose useful information by reasoning over the current context. We focus on the setup where a frozen large language model is prompted with few-shot in-context examples to generate both domain-specific actions and free-form language thoughts for task solving. The integration of reasoning and acting capabilities allows ReAct to show strong generalization to new task instances while learning solely from a few in-context examples."
        },
        {
            "title": "Knowledge-Intensive Tasks",
            "content": "We begin with knowledge-intensive reasoning tasks like multi-hop question answering and fact verification. By interacting with a Wikipedia API, ReAct is able to retrieve information to support reasoning, while also using reasoning to target what to retrieve next. We evaluate ReAct on two datasets: HotPotQA and FEVER, where models only receive the question/claim as input without access to support paragraphs."
        },
        {
            "title": "Decision Making Tasks",
            "content": "We also test ReAct on two language-based interactive decision-making tasks, ALFWorld and WebShop. Both environments require agents to act over long horizons with sparse rewards, warranting the need for reasoning to act and explore effectively. ReAct outperforms action-only methods by leveraging reasoning to identify relevant actions and maintain context throughout the task."
        },
        {
            "title": "Results & Observations",
            "content": "ReAct consistently outperforms baselines across various tasks, demonstrating the value of reasoning to guide acting. The empirical evaluations show that ReAct leads to superior performance with interpretable decision traces. We also analyze the limitations of ReAct under the prompting setup and perform initial fine-tuning experiments showing the potential of ReAct to improve with additional training data."
        },
        {
            "title": "Conclusion",
            "content": "We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Despite the simplicity of our method, complex tasks with large action spaces require more demonstrations to learn well. We explore the fine-tuning approach with initial promising results, but learning from more high-quality human annotations will be the desiderata to further improve the performance."
        }
    ]
}