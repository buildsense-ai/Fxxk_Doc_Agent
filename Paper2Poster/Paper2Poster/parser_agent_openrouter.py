#!/usr/bin/env python3
"""
æ”¯æŒOpenRouterçš„è§£ææ™ºèƒ½ä½“
å¯ä»¥ä½¿ç”¨OpenRouterä¸Šçš„å¤šç§æ¨¡å‹
"""

import argparse
import json
import os
import random
import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
from camel.models import ModelFactory
from camel.agents import ChatAgent
from camel.types import ModelPlatformType
from tenacity import retry, stop_after_attempt
from docling_core.types.doc.document import PictureItem, TableItem
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.document_converter import DocumentConverter, PdfFormatOption
from jinja2 import Template
from PIL import Image
import torch

# å°è¯•å¯¼å…¥markerï¼ˆå¯é€‰ï¼‰
try:
    from marker.models import create_model_dict
    from utils.src.model_utils import parse_pdf
    MARKER_AVAILABLE = True
except ImportError:
    MARKER_AVAILABLE = False
    print("Warning: Marker not available, will only use Docling for parsing")

# å°è¯•å¯¼å…¥CAMELå·¥å…·å‡½æ•°
try:
    from utils.wei_utils import get_agent_config, account_token
    from utils.src.utils import get_json_from_response
    CAMEL_UTILS_AVAILABLE = True
except ImportError:
    CAMEL_UTILS_AVAILABLE = False
    print("Warning: CAMEL utils not available, using simplified token counting")

load_dotenv()

# é…ç½®å¸¸é‡
IMAGE_RESOLUTION_SCALE = 5.0

# åˆå§‹åŒ–Doclingè½¬æ¢å™¨
from docling.datamodel.pipeline_options import EasyOcrOptions
from pathlib import Path

# è®¾ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„
models_cache_dir = Path("models_cache")
if models_cache_dir.exists():
    artifacts_path = str(models_cache_dir.absolute())
else:
    artifacts_path = None

pipeline_options = PdfPipelineOptions(
    ocr_options=EasyOcrOptions(),
    artifacts_path=artifacts_path
)
pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE
pipeline_options.generate_page_images = True
pipeline_options.generate_picture_images = True

doc_converter = DocumentConverter(
    format_options={
        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
    }
)

# OpenRouteræ”¯æŒçš„æ¨¡å‹é…ç½®
OPENROUTER_MODELS = {
    # OpenAIæ¨¡å‹
    "gpt-4o": {
        "model_type": "openai/gpt-4o",
        "model_config": {},
        "model_platform": "openai"
    },
    "gpt-4o-mini": {
        "model_type": "openai/gpt-4o-mini", 
        "model_config": {},
        "model_platform": "openai"
    },
    "gpt-3.5-turbo": {
        "model_type": "openai/gpt-3.5-turbo",
        "model_config": {},
        "model_platform": "openai"
    },
    # Anthropicæ¨¡å‹
    "claude-3.5-sonnet": {
        "model_type": "anthropic/claude-3.5-sonnet",
        "model_config": {},
        "model_platform": "openai"
    },
    "claude-3-haiku": {
        "model_type": "anthropic/claude-3-haiku",
        "model_config": {},
        "model_platform": "openai"
    },
    # Metaæ¨¡å‹
    "llama-3.1-8b": {
        "model_type": "meta-llama/llama-3.1-8b-instruct",
        "model_config": {},
        "model_platform": "openai"
    },
    "llama-3.1-70b": {
        "model_type": "meta-llama/llama-3.1-70b-instruct",
        "model_config": {},
        "model_platform": "openai"
    },
    # Googleæ¨¡å‹
    "gemini-pro": {
        "model_type": "google/gemini-pro",
        "model_config": {},
        "model_platform": "openai"
    },
    # å…¶ä»–å¼€æºæ¨¡å‹
    "qwen2.5-7b": {
        "model_type": "qwen/qwen2.5-7b-instruct",
        "model_config": {},
        "model_platform": "openai"
    },
    "qwen2.5-32b": {
        "model_type": "qwen/qwen2.5-32b-instruct",
        "model_config": {},
        "model_platform": "openai"
    }
}

class OpenRouterParserAgent:
    """æ”¯æŒOpenRouterçš„è§£ææ™ºèƒ½ä½“ç±»"""
    
    def __init__(self, model_name: str = "gpt-4o"):
        """
        åˆå§‹åŒ–è§£ææ™ºèƒ½ä½“
        
        Args:
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œæ”¯æŒOpenRouterä¸Šçš„å¤šç§æ¨¡å‹
        """
        self.model_name = model_name
        self.actor_config = self._get_agent_config(model_name)
        self.actor_model = self._create_model()
        self.actor_agent = self._create_agent()
        
    def _get_agent_config(self, model_name: str) -> Dict:
        """è·å–æ™ºèƒ½ä½“é…ç½®"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯OpenRouteræ¨¡å‹
        if model_name in OPENROUTER_MODELS:
            config = OPENROUTER_MODELS[model_name].copy()
            # è®¾ç½®OpenRouterçš„APIåœ°å€
            config["base_url"] = "https://openrouter.ai/api/v1"
            return config
        else:
            # ä½¿ç”¨CAMELå·¥å…·å‡½æ•°è·å–é…ç½®
            if CAMEL_UTILS_AVAILABLE:
                return get_agent_config(model_name)
            else:
                # ç®€åŒ–é…ç½®
                return {
                    "model_type": "gpt-4o",
                    "model_config": {},
                    "model_platform": "openai"
                }
    
    def _create_model(self):
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨OpenRouter
            if self.model_name in OPENROUTER_MODELS:
                # OpenRouteré…ç½®
                import os
                
                # æ£€æŸ¥APIå¯†é’¥
                openrouter_api_key = os.getenv('OPENROUTER_API_KEY') or os.getenv('OPENAI_API_KEY')
                if not openrouter_api_key:
                    raise ValueError("éœ€è¦è®¾ç½®OPENROUTER_API_KEYæˆ–OPENAI_API_KEYç¯å¢ƒå˜é‡")
                
                print(f"ğŸ”‘ ä½¿ç”¨APIå¯†é’¥: {openrouter_api_key[:10]}...")
                
                # ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®©OpenAIæ¨¡å‹è¿æ¥åˆ°OpenRouter
                original_base_url = os.environ.get('OPENAI_API_BASE_URL')
                original_api_key = os.environ.get('OPENAI_API_KEY')
                
                os.environ['OPENAI_API_BASE_URL'] = 'https://openrouter.ai/api/v1'
                os.environ['OPENAI_API_KEY'] = openrouter_api_key
                
                try:
                    # ä½¿ç”¨æ ‡å‡†OpenAIæ¨¡å‹ï¼Œä½†é€šè¿‡ç¯å¢ƒå˜é‡é‡å®šå‘åˆ°OpenRouter
                    from camel.configs.openai_config import ChatGPTConfig
                    
                    model = ModelFactory.create(
                        model_platform=ModelPlatformType.OPENAI,
                        model_type=self.model_name,
                        model_config_dict=self.actor_config['model_config'] or ChatGPTConfig().as_dict(),
                    )
                    
                    print(f"âœ… æˆåŠŸåˆ›å»ºOpenRouteræ¨¡å‹: {self.model_name}")
                    
                finally:
                    # æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡
                    if original_base_url:
                        os.environ['OPENAI_API_BASE_URL'] = original_base_url
                    elif 'OPENAI_API_BASE_URL' in os.environ:
                        del os.environ['OPENAI_API_BASE_URL']
                    
                    if original_api_key:
                        os.environ['OPENAI_API_KEY'] = original_api_key
                    elif original_api_key is None and 'OPENAI_API_KEY' in os.environ:
                        del os.environ['OPENAI_API_KEY']
                
                return model
            else:
                # è·å–æ­£ç¡®çš„å¹³å°ç±»å‹
                platform_str = self.actor_config['model_platform']
                if isinstance(platform_str, str):
                    # è½¬æ¢å­—ç¬¦ä¸²åˆ°æšä¸¾ç±»å‹
                    platform = ModelPlatformType(platform_str)
                else:
                    platform = platform_str
                
                # ä½¿ç”¨åŸå§‹é…ç½®
                if self.model_name.startswith('vllm_qwen'):
                    return ModelFactory.create(
                        model_platform=platform,
                        model_type=self.actor_config['model_type'],
                        model_config_dict=self.actor_config['model_config'],
                        url=self.actor_config['url'],
                    )
                else:
                    return ModelFactory.create(
                        model_platform=platform,
                        model_type=self.actor_config['model_type'],
                        model_config_dict=self.actor_config['model_config'],
                    )
        except Exception as e:
            print(f"Error creating model: {e}")
            return None
    
    def _create_agent(self) -> ChatAgent:
        """åˆ›å»ºèŠå¤©æ™ºèƒ½ä½“"""
        actor_sys_msg = 'You are the author of the paper, and you will create a poster for the paper.'
        
        return ChatAgent(
            system_message=actor_sys_msg,
            model=self.actor_model,
            message_window_size=10,
            token_limit=self.actor_config.get('token_limit', None)
        )
    
    def _account_token(self, response) -> Tuple[int, int]:
        """è®¡ç®—tokenä½¿ç”¨é‡"""
        if CAMEL_UTILS_AVAILABLE:
            return account_token(response)
        else:
            # ç®€åŒ–ç‰ˆæœ¬ï¼Œè¿”å›ä¼°è®¡å€¼
            return len(str(response)), len(str(response))
    
    def _get_json_from_response(self, content: str) -> Dict:
        """ä»å“åº”ä¸­æå–JSON"""
        if CAMEL_UTILS_AVAILABLE:
            return get_json_from_response(content)
        else:
            # ç®€åŒ–ç‰ˆæœ¬
            try:
                # å°è¯•ç›´æ¥è§£æJSON
                return json.loads(content)
            except:
                # å°è¯•æå–JSONä»£ç å—
                import re
                json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group(1))
                else:
                    # å°è¯•æå–{}åŒ…å›´çš„å†…å®¹
                    brace_match = re.search(r'\{.*\}', content, re.DOTALL)
                    if brace_match:
                        return json.loads(brace_match.group(0))
                    else:
                        raise ValueError("Could not extract JSON from response")

    @retry(stop=stop_after_attempt(5))
    def parse_raw(self, pdf_path: str, output_dir: str = "parser_output") -> Tuple[Dict, Dict, Dict]:
        """
        è§£æPDFæ–‡ä»¶
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            Tuple[Dict, Dict, Dict]: (content_json, images, tables)
        """
        print(f"å¼€å§‹è§£æPDF: {pdf_path}")
        print(f"ä½¿ç”¨æ¨¡å‹: {self.model_name}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨Doclingè§£æPDF
        print("ä½¿ç”¨Doclingè§£æPDF...")
        raw_result = doc_converter.convert(pdf_path)
        raw_markdown = raw_result.document.export_to_markdown()
        
        # æ¸…ç†markdownå†…å®¹
        markdown_clean_pattern = re.compile(r"<!--[\s\S]*?-->")
        text_content = markdown_clean_pattern.sub("", raw_markdown)
        
        # æ£€æŸ¥è§£æç»“æœ
        if len(text_content) < 500:
            print("Doclingè§£æç»“æœè¿‡çŸ­ï¼Œå°è¯•ä½¿ç”¨Marker...")
            if MARKER_AVAILABLE:
                parser_model = create_model_dict(device='cuda', dtype=torch.float16)
                text_content, rendered = parse_pdf(pdf_path, model_lst=parser_model, save_file=False)
            else:
                print("Warning: Markerä¸å¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨Doclingç»“æœ")
        
        print(f"è§£æå¾—åˆ°æ–‡æœ¬é•¿åº¦: {len(text_content)} å­—ç¬¦")
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨LLMé‡æ–°ç»„ç»‡å†…å®¹
        print("ä½¿ç”¨LLMé‡æ–°ç»„ç»‡å†…å®¹...")
        content_json = self._reorganize_content_with_llm(text_content)
        
        # ç¬¬ä¸‰æ­¥ï¼šæå–å›¾ç‰‡å’Œè¡¨æ ¼
        print("æå–å›¾ç‰‡å’Œè¡¨æ ¼...")
        images, tables = self._extract_images_and_tables(raw_result, output_dir)
        
        # ä¿å­˜ç»“æœ
        self._save_results(content_json, images, tables, output_dir)
        
        return content_json, images, tables
    
    def _reorganize_content_with_llm(self, text_content: str) -> Dict:
        """ä½¿ç”¨LLMé‡æ–°ç»„ç»‡å†…å®¹"""
        # åŠ è½½æç¤ºæ¨¡æ¿
        template_content = self._get_prompt_template()
        template = Template(template_content)
        
        # ç”Ÿæˆæç¤º
        prompt = template.render(markdown_document=text_content)
        
        # è°ƒç”¨LLM
        while True:
            self.actor_agent.reset()
            response = self.actor_agent.step(prompt)
            input_token, output_token = self._account_token(response)
            
            print(f"LLMè°ƒç”¨å®Œæˆ - è¾“å…¥tokens: {input_token}, è¾“å‡ºtokens: {output_token}")
            
            try:
                content_json = self._get_json_from_response(response.msgs[0].content)
                
                if len(content_json) > 0:
                    # éªŒè¯å’Œä¼˜åŒ–ç»“æœ
                    content_json = self._validate_and_optimize_content(content_json)
                    return content_json
                else:
                    print("LLMè¿”å›ç©ºç»“æœï¼Œé‡è¯•...")
                    
            except Exception as e:
                print(f"è§£æLLMå“åº”å¤±è´¥: {e}")
                print("é‡è¯•...")
                
                # å¦‚æœå†…å®¹å¤ªé•¿ï¼Œæˆªæ–­é‡è¯•
                if self.model_name.startswith('vllm_qwen'):
                    text_content = text_content[:80000]
                    prompt = template.render(markdown_document=text_content)
    
    def _get_prompt_template(self) -> str:
        """è·å–æç¤ºæ¨¡æ¿"""
        return """You are a document content divider and extractor specialist, expert in dividing and extracting content from various types of documents and reorganizing it into a two-level json format for later poster generation.

Based on given markdown document, generate a JSON output for later poster generation, make sure the output is concise and focused.

Step-by-Step Instructions:
1. Identify Sections and Subsections in document and identify sections and subsections based on the heading levels and logical structure.

2. Divide Content: Reorganize the content into sections and subsections, ensuring that each subsection contains approximately 500 words.

3. Refine Titles: Create titles for each section with at most 3 words.

4. Remove Unwanted Elements: Eliminate any unwanted elements such as headers, footers, text surrounded by `~~` indicating deletion.

5. Refine Text: For content, you should keep as much raw text as possible. Do not include citations.

6. Length: you should control the length of each section, according to their importance according to your understanding of the paper. For important sections, their content should be long.

7. Make sure there is a poster title section at the beginning, and it should contain information like paper title, author, organization etc.

8. The "meta" key contains the meta information of the poster, where the title should be the raw title of the paper and is not summarized.

9. There **must** be a section for the poster title.

Example Output:
{
    "meta": {
        "poster_title": "raw title of the paper",
        "authors": "authors of the paper",
        "affiliations": "affiliations of the authors"
    },
    "sections": [
        {
            "title": "Poster Title & Author",
            "content": "content of poster title and author"
        },
        {
            "title": "title of section1",
            "content": "content of section 1"
        },
        {
            "title": "title of section2",
            "content": "content of section 2"
        }
    ]
}

Give your output in JSON format
Input:
{{ markdown_document }}
Output:"""
    
    def _validate_and_optimize_content(self, content_json: Dict) -> Dict:
        """éªŒè¯å’Œä¼˜åŒ–å†…å®¹"""
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if 'sections' not in content_json:
            raise ValueError("Missing 'sections' field in response")
        
        # éªŒè¯æ¯ä¸ªsectionçš„æ ¼å¼
        has_title = False
        for section in content_json['sections']:
            if not isinstance(section, dict) or 'title' not in section or 'content' not in section:
                raise ValueError("Invalid section format")
            if 'title' in section['title'].lower():
                has_title = True
        
        if not has_title:
            raise ValueError("Missing title section")
        
        # å¦‚æœsectionè¿‡å¤šï¼Œè¿›è¡Œæ™ºèƒ½é€‰æ‹©
        if len(content_json['sections']) > 9:
            print(f"Sectionæ•°é‡è¿‡å¤š({len(content_json['sections'])}ä¸ª)ï¼Œè¿›è¡Œæ™ºèƒ½é€‰æ‹©...")
            selected_sections = (
                content_json['sections'][:2] + 
                random.sample(content_json['sections'][2:-2], 5) + 
                content_json['sections'][-2:]
            )
            content_json['sections'] = selected_sections
            print(f"é€‰æ‹©åå‰©ä½™{len(content_json['sections'])}ä¸ªsections")
        
        return content_json
    
    def _extract_images_and_tables(self, raw_result, output_dir: str) -> Tuple[Dict, Dict]:
        """æå–å›¾ç‰‡å’Œè¡¨æ ¼"""
        images = {}
        tables = {}
        
        # æå–è¡¨æ ¼
        table_counter = 0
        for element, _level in raw_result.document.iterate_items():
            if isinstance(element, TableItem):
                table_counter += 1
                caption = element.caption_text(raw_result.document)
                # ç§»é™¤captioné•¿åº¦é™åˆ¶ï¼Œæå–æ‰€æœ‰è¡¨æ ¼
                table_img_path = os.path.join(output_dir, f"table-{table_counter}.png")
                
                # ä¿å­˜è¡¨æ ¼å›¾ç‰‡
                try:
                    table_image = element.get_image(raw_result.document)
                    if table_image is not None:
                        with open(table_img_path, "wb") as fp:
                            table_image.save(fp, "PNG")
                        
                        # è·å–å›¾ç‰‡ä¿¡æ¯
                        table_img = Image.open(table_img_path)
                        tables[str(table_counter)] = {
                            'caption': caption if caption else f"è¡¨æ ¼ {table_counter}",
                            'table_path': table_img_path,
                            'width': table_img.width,
                            'height': table_img.height,
                            'figure_size': table_img.width * table_img.height,
                            'figure_aspect': table_img.width / table_img.height,
                        }
                        print(f"âœ… ä¿å­˜è¡¨æ ¼ {table_counter}: {table_img_path}")
                    else:
                        print(f"âš ï¸ è¡¨æ ¼ {table_counter} å›¾åƒä¸ºç©º")
                except Exception as e:
                    print(f"âŒ ä¿å­˜è¡¨æ ¼ {table_counter} å¤±è´¥: {e}")
        
        # æå–å›¾ç‰‡
        picture_counter = 0
        # æ–°å¢ï¼šæ”¶é›†æ‰€æœ‰å…ƒç´ ï¼Œä¾¿äºå®šä½å›¾ç‰‡å’Œæ–‡æœ¬
        all_elements = list(raw_result.document.iterate_items())
        for idx, (element, _level) in enumerate(all_elements):
            if isinstance(element, PictureItem):
                picture_counter += 1
                caption = element.caption_text(raw_result.document)
                image_img_path = os.path.join(output_dir, f"picture-{picture_counter}.png")
                try:
                    picture_image = element.get_image(raw_result.document)
                    if picture_image is not None:
                        with open(image_img_path, "wb") as fp:
                            picture_image.save(fp, "PNG")
                        image_img = Image.open(image_img_path)
                        # æ–°å¢ï¼šæå–å‰å2ä¸ªTextItemæ–‡æœ¬
                        context_texts = []
                        # å‘å‰æ‰¾2ä¸ªTextItem
                        prev = idx - 1
                        found = 0
                        while prev >= 0 and found < 2:
                            prev_elem, _ = all_elements[prev]
                            if hasattr(prev_elem, 'text') and prev_elem.text:
                                context_texts.insert(0, prev_elem.text.strip())
                                found += 1
                            prev -= 1
                        # å‘åæ‰¾2ä¸ªTextItem
                        next_ = idx + 1
                        found = 0
                        while next_ < len(all_elements) and found < 2:
                            next_elem, _ = all_elements[next_]
                            if hasattr(next_elem, 'text') and next_elem.text:
                                context_texts.append(next_elem.text.strip())
                                found += 1
                            next_ += 1
                        context = '\n'.join([t for t in context_texts if t])
                        images[str(picture_counter)] = {
                            'caption': caption if caption else f"å›¾ç‰‡ {picture_counter}",
                            'image_path': image_img_path,
                            'width': image_img.width,
                            'height': image_img.height,
                            'figure_size': image_img.width * image_img.height,
                            'figure_aspect': image_img.width / image_img.height,
                            'context': context,
                        }
                        print(f"âœ… ä¿å­˜å›¾ç‰‡ {picture_counter}: {image_img_path}")
                    else:
                        print(f"âš ï¸ å›¾ç‰‡ {picture_counter} å›¾åƒä¸ºç©º")
                except Exception as e:
                    print(f"âŒ ä¿å­˜å›¾ç‰‡ {picture_counter} å¤±è´¥: {e}")
        
        print(f"æå–äº† {len(tables)} ä¸ªè¡¨æ ¼å’Œ {len(images)} ä¸ªå›¾ç‰‡")
        return images, tables
    
    def _save_results(self, content_json: Dict, images: Dict, tables: Dict, output_dir: str):
        """ä¿å­˜è§£æç»“æœ"""
        # ä¿å­˜ç»“æ„åŒ–å†…å®¹
        content_path = os.path.join(output_dir, "parsed_content.json")
        with open(content_path, 'w', encoding='utf-8') as f:
            json.dump(content_json, f, indent=4, ensure_ascii=False)
        print(f"ç»“æ„åŒ–å†…å®¹å·²ä¿å­˜åˆ°: {content_path}")
        
        # ä¿å­˜å›¾ç‰‡ä¿¡æ¯
        images_path = os.path.join(output_dir, "images.json")
        with open(images_path, 'w', encoding='utf-8') as f:
            json.dump(images, f, indent=4, ensure_ascii=False)
        print(f"å›¾ç‰‡ä¿¡æ¯å·²ä¿å­˜åˆ°: {images_path}")
        
        # ä¿å­˜è¡¨æ ¼ä¿¡æ¯
        tables_path = os.path.join(output_dir, "tables.json")
        with open(tables_path, 'w', encoding='utf-8') as f:
            json.dump(tables, f, indent=4, ensure_ascii=False)
        print(f"è¡¨æ ¼ä¿¡æ¯å·²ä¿å­˜åˆ°: {tables_path}")
        
        # ä¿å­˜æ±‡æ€»ä¿¡æ¯
        summary = {
            "total_sections": len(content_json.get("sections", [])),
            "total_images": len(images),
            "total_tables": len(tables),
            "meta_info": content_json.get("meta", {}),
            "section_titles": [section.get("title", "") for section in content_json.get("sections", [])],
            "model_used": self.model_name
        }
        
        summary_path = os.path.join(output_dir, "summary.json")
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=4, ensure_ascii=False)
        print(f"æ±‡æ€»ä¿¡æ¯å·²ä¿å­˜åˆ°: {summary_path}")
    
    def get_parsing_stats(self, content_json: Dict, images: Dict, tables: Dict) -> Dict:
        """è·å–è§£æç»Ÿè®¡ä¿¡æ¯"""
        total_text_length = sum(len(section.get("content", "")) for section in content_json.get("sections", []))
        
        stats = {
            "sections_count": len(content_json.get("sections", [])),
            "total_text_length": total_text_length,
            "avg_section_length": total_text_length / max(len(content_json.get("sections", [])), 1),
            "images_count": len(images),
            "tables_count": len(tables),
            "total_figures": len(images) + len(tables),
            "has_meta": "meta" in content_json,
            "has_title_section": any("title" in section.get("title", "").lower() for section in content_json.get("sections", [])),
            "section_titles": [section.get("title", "") for section in content_json.get("sections", [])],
            "model_used": self.model_name
        }
        
        return stats


def list_available_models():
    """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹"""
    print("ğŸ”„ OpenRouteræ”¯æŒçš„æ¨¡å‹:")
    print("=" * 50)
    
    categories = {
        "OpenAIæ¨¡å‹": ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"],
        "Anthropicæ¨¡å‹": ["claude-3.5-sonnet", "claude-3-haiku"],
        "Metaæ¨¡å‹": ["llama-3.1-8b", "llama-3.1-70b"],
        "Googleæ¨¡å‹": ["gemini-pro"],
        "å¼€æºæ¨¡å‹": ["qwen2.5-7b", "qwen2.5-32b"]
    }
    
    for category, models in categories.items():
        print(f"\nğŸ“‹ {category}:")
        for model in models:
            print(f"  â€¢ {model}")
    
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•: python parser_agent_openrouter.py paper.pdf --model gpt-4o")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ”¯æŒOpenRouterçš„è§£ææ™ºèƒ½ä½“")
    parser.add_argument("pdf_path", help="PDFæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output_dir", default="parser_output", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--model", default="gpt-4o", help="ä½¿ç”¨çš„æ¨¡å‹åç§°")
    parser.add_argument("--list-models", action="store_true", help="åˆ—å‡ºå¯ç”¨æ¨¡å‹")
    parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # åˆ—å‡ºå¯ç”¨æ¨¡å‹
    if args.list_models:
        list_available_models()
        return
    
    # æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.pdf_path):
        print(f"é”™è¯¯: PDFæ–‡ä»¶ä¸å­˜åœ¨: {args.pdf_path}")
        return
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®æ‚¨çš„OpenRouter APIå¯†é’¥:")
        print("echo 'OPENAI_API_KEY=sk-or-...' > .env")
        return
    
    try:
        # åˆ›å»ºè§£ææ™ºèƒ½ä½“
        print(f"åˆå§‹åŒ–è§£ææ™ºèƒ½ä½“ï¼Œä½¿ç”¨æ¨¡å‹: {args.model}")
        parser_agent = OpenRouterParserAgent(model_name=args.model)
        
        # æ‰§è¡Œè§£æ
        content_json, images, tables = parser_agent.parse_raw(args.pdf_path, args.output_dir)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = parser_agent.get_parsing_stats(content_json, images, tables)
        
        # è¾“å‡ºç»“æœ
        print("\n" + "="*50)
        print("è§£æå®Œæˆï¼")
        print("="*50)
        
        print(f"ğŸ“„ è§£æç»Ÿè®¡:")
        print(f"  - ä½¿ç”¨æ¨¡å‹: {stats['model_used']}")
        print(f"  - Sectionsæ•°é‡: {stats['sections_count']}")
        print(f"  - æ€»æ–‡æœ¬é•¿åº¦: {stats['total_text_length']:,} å­—ç¬¦")
        print(f"  - å¹³å‡sectioné•¿åº¦: {stats['avg_section_length']:.0f} å­—ç¬¦")
        print(f"  - å›¾ç‰‡æ•°é‡: {stats['images_count']}")
        print(f"  - è¡¨æ ¼æ•°é‡: {stats['tables_count']}")
        print(f"  - æ€»å›¾è¡¨æ•°é‡: {stats['total_figures']}")
        
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  - ç»“æ„åŒ–å†…å®¹: {args.output_dir}/parsed_content.json")
        print(f"  - å›¾ç‰‡ä¿¡æ¯: {args.output_dir}/images.json")
        print(f"  - è¡¨æ ¼ä¿¡æ¯: {args.output_dir}/tables.json")
        print(f"  - æ±‡æ€»ä¿¡æ¯: {args.output_dir}/summary.json")
        
        if args.verbose:
            print(f"\nğŸ“‹ Sectionæ ‡é¢˜:")
            for i, title in enumerate(stats['section_titles'], 1):
                print(f"  {i}. {title}")
            
            if content_json.get("meta"):
                print(f"\nğŸ“ è®ºæ–‡ä¿¡æ¯:")
                meta = content_json["meta"]
                print(f"  - æ ‡é¢˜: {meta.get('poster_title', 'N/A')}")
                print(f"  - ä½œè€…: {meta.get('authors', 'N/A')}")
                print(f"  - æœºæ„: {meta.get('affiliations', 'N/A')}")
        
        print(f"\nâœ… è§£ææˆåŠŸå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ è§£æå¤±è´¥: {e}")
        import traceback
        if args.verbose:
            traceback.print_exc()


if __name__ == "__main__":
    main() 