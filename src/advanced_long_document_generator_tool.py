#!/usr/bin/env python3
"""
é«˜çº§é•¿æ–‡æ¡£ç”Ÿæˆå·¥å…·
åŸºäºlong_generatoré¡¹ç›®å°è£…çš„ä¸“ä¸šé•¿æ–‡æ¡£ç”Ÿæˆå™¨
"""

import json
import os
import time
import uuid
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
import docx
from docx.shared import Pt
from docx.oxml.ns import qn

# å¯¼å…¥å¿…è¦çš„åº“
try:
    import openai
    import requests
    import urllib.parse
    from minio import Minio
    from minio.error import S3Error
except ImportError as e:
    logging.warning(f"éƒ¨åˆ†ä¾èµ–åº“æœªå®‰è£…: {e}")

from .tools import Tool

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AdvancedLongDocumentConfig:
    """é«˜çº§é•¿æ–‡æ¡£ç”Ÿæˆå™¨é…ç½®"""
    
    def __init__(self):
        # ä»»åŠ¡çŠ¶æ€æ–‡ä»¶å­˜å‚¨ç›®å½•
        self.TASKS_DIR = "long_document_tasks"
        
        # DeepSeek APIé…ç½®
        self.DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENROUTER_API_KEY")
        self.DEEPSEEK_API_BASE = "https://api.deepseek.com/v1"
        self.AI_MODEL_NAME = "deepseek-chat"
        
        # å¤§çº²ç²¾ç‚¼çš„æœ€å¤§å¾ªç¯æ¬¡æ•°
        self.MAX_REFINEMENT_CYCLES = 3
        
        # å‘é‡æœç´¢APIé…ç½®
        self.SEARCH_API_BASE = "http://43.139.19.144:3000"
        self.SEARCH_API_TOP_K = 5
        
        # MinIOäº‘å­˜å‚¨é…ç½®
        self.MINIO_ENDPOINT = "43.139.19.144:9000"
        self.MINIO_ACCESS_KEY = "minioadmin"
        self.MINIO_SECRET_KEY = "minioadmin"
        self.MINIO_BUCKET_NAME = "docs"
        self.MINIO_USE_SECURE = False
        
        # ç¡®ä¿ä»»åŠ¡ç›®å½•å­˜åœ¨
        os.makedirs(self.TASKS_DIR, exist_ok=True)

class TaskState:
    """ä»»åŠ¡çŠ¶æ€ç®¡ç†å™¨"""
    
    def __init__(self, task_id: str, config: AdvancedLongDocumentConfig):
        self.task_id = task_id
        self.config = config
        self.filepath = os.path.join(config.TASKS_DIR, f"task_{task_id}.json")
        self.data: Dict[str, Any] = {}
    
    def load(self) -> bool:
        """åŠ è½½ä»»åŠ¡çŠ¶æ€"""
        if os.path.exists(self.filepath):
            try:
                with open(self.filepath, 'r', encoding='utf-8') as f:
                    self.data = json.load(f)
                return True
            except Exception as e:
                logger.error(f"åŠ è½½ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        return False
    
    def save(self):
        """ä¿å­˜ä»»åŠ¡çŠ¶æ€"""
        try:
            self.data['lastUpdatedTimestamp'] = datetime.now().isoformat()
            with open(self.filepath, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, ensure_ascii=False, indent=2)
            logger.info(f"ä»»åŠ¡çŠ¶æ€å·²ä¿å­˜: {self.filepath}")
        except Exception as e:
            logger.error(f"ä¿å­˜ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
    
    def initialize(self, initial_request: Dict[str, str]):
        """åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€"""
        self.data = {
            "taskId": self.task_id,
            "status": "pending",
            "progressPercentage": 0,
            "currentStatusMessage": "ä»»åŠ¡å·²åˆ›å»ºï¼Œç­‰å¾…åˆå§‹åŒ–...",
            "initialRequest": initial_request,
            "creativeBrief": "",
            "projectName": "",
            "outline": {},
            "finalDocument": "",
            "docxPublicUrl": "",
            "docxLocalPath": "",
            "errorLog": []
        }
        self.save()
    
    def update_status(self, status: str, message: str, progress: int):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        self.data['status'] = status
        self.data['currentStatusMessage'] = message
        self.data['progressPercentage'] = progress
        self.save()
        logger.info(f"è¿›åº¦æ›´æ–°: {progress}% - {message}")
    
    def log_error(self, stage: str, error_message: str):
        """è®°å½•é”™è¯¯"""
        self.data['errorLog'].append({
            "timestamp": datetime.now().isoformat(),
            "stage": stage,
            "message": error_message
        })
        self.update_status("failed", f"åœ¨ {stage} é˜¶æ®µå‘ç”Ÿé”™è¯¯ã€‚", self.data.get('progressPercentage', 0))

class AIService:
    """AIæœåŠ¡å°è£…"""
    
    def __init__(self, config: AdvancedLongDocumentConfig):
        self.config = config
    
    def call_ai_model(self, prompt: str, context: str = None, expect_json: bool = False) -> Dict[str, Any]:
        """è°ƒç”¨AIæ¨¡å‹"""
        if not self.config.DEEPSEEK_API_KEY:
            raise ValueError("æœªè®¾ç½®DEEPSEEK_API_KEYæˆ–OPENROUTER_API_KEYç¯å¢ƒå˜é‡")
        
        try:
            # åˆ›å»ºhttpxå®¢æˆ·ç«¯ï¼Œç¦ç”¨ä»£ç†ä»¥é¿å…è¿æ¥é—®é¢˜ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´
            import httpx
            http_client = httpx.Client(
                timeout=120.0,  # å¢åŠ åˆ°2åˆ†é’Ÿè¶…æ—¶
                limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
            )
            client = openai.OpenAI(
                api_key=self.config.DEEPSEEK_API_KEY,
                base_url=self.config.DEEPSEEK_API_BASE,
                http_client=http_client,
                timeout=120.0  # OpenAIå®¢æˆ·ç«¯ä¹Ÿè®¾ç½®2åˆ†é’Ÿè¶…æ—¶
            )
        except Exception as e:
            raise Exception(f"åˆå§‹åŒ–AIå®¢æˆ·ç«¯å¤±è´¥: {e}")
        
        messages = []
        if context:
            messages.append({"role": "system", "content": context})
        messages.append({"role": "user", "content": prompt})
        
        logger.info(f"è°ƒç”¨AIæ¨¡å‹: {self.config.AI_MODEL_NAME}")
        
        api_params = {
            "model": self.config.AI_MODEL_NAME,
            "messages": messages
        }
        if expect_json:
            api_params['response_format'] = {'type': 'json_object'}
        
        try:
            response = client.chat.completions.create(**api_params)
            response_content = response.choices[0].message.content
            
            if expect_json:
                return json.loads(response_content)
            else:
                return {'text': response_content}
                
        except Exception as e:
            raise Exception(f"AIæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
    
    def search_vectordata(self, query: str, top_k: int = None) -> List[str]:
        """æœç´¢å‘é‡æ•°æ®åº“"""
        if top_k is None:
            top_k = self.config.SEARCH_API_TOP_K
            
        logger.info(f"æœç´¢å‘é‡æ•°æ®åº“: {query}")
        
        try:
            base_url = f"{self.config.SEARCH_API_BASE}/search-drawings"
            encoded_query = urllib.parse.quote(query)
            full_url = f"{base_url}?query={encoded_query}&top_k={top_k}"
            
            headers = {'accept': 'application/json'}
            # ç¦ç”¨ä»£ç†ä»¥é¿å…è¿æ¥é—®é¢˜
            proxies = {'http': '', 'https': ''}
            response = requests.get(full_url, headers=headers, timeout=20, proxies=proxies)
            response.raise_for_status()
            
            data = response.json()
            results = data.get("results", [])
            content_list = [item.get("content", "") for item in results if item.get("content")]
            
            logger.info(f"å‘é‡æœç´¢æˆåŠŸï¼Œè·å¾— {len(content_list)} æ¡ç»“æœ")
            return content_list
            
        except Exception as e:
            logger.warning(f"å‘é‡æœç´¢å¤±è´¥: {e}")
            return []

class DocumentService:
    """æ–‡æ¡£æœåŠ¡"""
    
    def __init__(self, config: AdvancedLongDocumentConfig):
        self.config = config
    
    def create_docx(self, final_text: str, project_name: str, task_id: str) -> str:
        """åˆ›å»ºDOCXæ–‡æ¡£"""
        try:
            doc = docx.Document()
            
            # è®¾ç½®é»˜è®¤å­—ä½“ä¸ºå®‹ä½“
            style = doc.styles['Normal']
            font = style.font
            font.name = 'å®‹ä½“'
            font.size = Pt(12)
            style.element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
            
            # æ·»åŠ ä¸»æ ‡é¢˜
            title_heading = doc.add_heading(project_name or 'ç”Ÿæˆæ–‡æ¡£', level=0)
            for run in title_heading.runs:
                run.font.name = 'å®‹ä½“'
                run.font.size = Pt(18)
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
            
            def set_font_style(element, font_size=12):
                """è®¾ç½®å­—ä½“æ ·å¼"""
                try:
                    if hasattr(element, 'runs'):
                        for run in element.runs:
                            run.font.name = 'å®‹ä½“'
                            run.font.size = Pt(font_size)
                            run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
                        if not element.runs:
                            run = element.add_run()
                            run.font.name = 'å®‹ä½“'
                            run.font.size = Pt(font_size)
                            run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
                except Exception as e:
                    logger.warning(f"è®¾ç½®å­—ä½“æ ·å¼å¤±è´¥: {e}")
            
            # æ·»åŠ å†…å®¹
            for line in final_text.split('\n'):
                stripped_line = line.strip()
                if stripped_line.startswith('## '):
                    heading_text = stripped_line.replace('## ', '', 1)
                    heading = doc.add_heading(heading_text, level=2)
                    set_font_style(heading, 14)
                elif stripped_line:
                    paragraph = doc.add_paragraph(stripped_line)
                    set_font_style(paragraph, 12)
            
            # ä¿å­˜æ–‡æ¡£
            docx_filename = f"task_{task_id}.docx"
            docx_filepath = os.path.join(self.config.TASKS_DIR, docx_filename)
            doc.save(docx_filepath)
            
            logger.info(f"DOCXæ–‡æ¡£å·²ä¿å­˜: {docx_filepath}")
            return docx_filepath
            
        except Exception as e:
            logger.error(f"åˆ›å»ºDOCXå¤±è´¥: {e}")
            raise
    
    def upload_to_minio(self, file_path: str, object_name: str) -> Optional[str]:
        """ä¸Šä¼ æ–‡ä»¶åˆ°MinIO"""
        try:
            client = Minio(
                self.config.MINIO_ENDPOINT,
                access_key=self.config.MINIO_ACCESS_KEY,
                secret_key=self.config.MINIO_SECRET_KEY,
                secure=self.config.MINIO_USE_SECURE
            )
            
            bucket_name = self.config.MINIO_BUCKET_NAME
            if not client.bucket_exists(bucket_name):
                client.make_bucket(bucket_name)
                logger.info(f"åˆ›å»ºå­˜å‚¨æ¡¶: {bucket_name}")
            
            client.fput_object(bucket_name, object_name, file_path)
            
            public_url = f"http://{self.config.MINIO_ENDPOINT}/{bucket_name}/{object_name}"
            logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {public_url}")
            return public_url
            
        except Exception as e:
            logger.warning(f"ä¸Šä¼ åˆ°MinIOå¤±è´¥: {e}")
            return None

class AdvancedLongDocumentGenerator:
    """é«˜çº§é•¿æ–‡æ¡£ç”Ÿæˆå™¨"""
    
    def __init__(self, task_id: Optional[str] = None):
        self.task_id = task_id or str(uuid.uuid4())
        self.config = AdvancedLongDocumentConfig()
        self.state = TaskState(self.task_id, self.config)
        self.ai_service = AIService(self.config)
        self.doc_service = DocumentService(self.config)
    
    def generate_document(self, request: str, chathistory: str = "") -> Dict[str, Any]:
        """ç”Ÿæˆé•¿æ–‡æ¡£çš„ä¸»è¦æ–¹æ³•"""
        try:
            logger.info(f"å¼€å§‹ç”Ÿæˆé•¿æ–‡æ¡£ï¼Œä»»åŠ¡ID: {self.task_id}")
            
            # åˆå§‹åŒ–ä»»åŠ¡
            self.state.initialize({
                "chathistory": chathistory,
                "request": request
            })
            
            # æ‰§è¡Œç”Ÿæˆæµç¨‹
            self._run_generation_pipeline()
            
            # è¿”å›ç»“æœ
            return {
                "success": True,
                "task_id": self.task_id,
                "status": self.state.data.get("status"),
                "progress": self.state.data.get("progressPercentage"),
                "message": self.state.data.get("currentStatusMessage"),
                "docx_url": self.state.data.get("docxPublicUrl"),
                "docx_path": self.state.data.get("docxLocalPath"),
                "final_document": self.state.data.get("finalDocument", "")[:500] + "..." if len(self.state.data.get("finalDocument", "")) > 500 else self.state.data.get("finalDocument", "")
            }
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ–‡æ¡£å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "task_id": self.task_id
            }
    
    def _run_generation_pipeline(self):
        """æ‰§è¡Œç”Ÿæˆæµç¨‹"""
        try:
            # é˜¶æ®µ1: å‡†å¤‡åˆ›ä½œæŒ‡ä»¤
            self._prepare_creative_brief()
            
            # é˜¶æ®µ2: ç”Ÿæˆåˆå§‹å¤§çº²
            self._generate_initial_outline()
            
            # é˜¶æ®µ3: ç²¾ç‚¼å¤§çº²
            self._refine_outline()
            
            # é˜¶æ®µ4: ç”Ÿæˆç« èŠ‚å†…å®¹
            self._generate_chapters()
            
            # é˜¶æ®µ5: ç»„è£…æœ€ç»ˆæ–‡æ¡£
            self._assemble_final_document()
            
        except Exception as e:
            self.state.log_error("pipeline", str(e))
            raise
    
    def _prepare_creative_brief(self):
        """å‡†å¤‡åˆ›ä½œæŒ‡ä»¤"""
        self.state.update_status("brief_generation", "æ­£åœ¨åˆ†æéœ€æ±‚å¹¶ç”Ÿæˆåˆ›ä½œæŒ‡ä»¤...", 5)
        
        chathistory = self.state.data['initialRequest']['chathistory']
        request = self.state.data['initialRequest']['request']
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è§„åˆ’åŠ©ç†ã€‚è¯·æ ¹æ®ä¸‹é¢çš„èŠå¤©è®°å½•å’Œç”¨æˆ·çš„æœ€ç»ˆè¯·æ±‚ï¼Œæç‚¼å¹¶ç”Ÿæˆä¸€ä»½è¯¦å°½çš„ã€ç”¨äºæŒ‡å¯¼åç»­é•¿æ–‡å†™ä½œçš„"åˆ›ä½œæŒ‡ä»¤"ï¼ˆCreative Briefï¼‰ã€‚
è¿™ä»½æŒ‡ä»¤åº”è¯¥æ¸…æ™°ã€ç»“æ„åŒ–ï¼Œå¹¶ç»¼åˆæ‰€æœ‰å·²çŸ¥ä¿¡æ¯ã€‚

ã€èŠå¤©è®°å½•ã€‘
{chathistory}

ã€ç”¨æˆ·æœ€ç»ˆè¯·æ±‚ã€‘
{request}

è¯·ä»¥JSONæ ¼å¼è¿”å›ä½ çš„åˆ†æç»“æœï¼ŒåŒ…å«ä¸€ä¸ª'creative_brief'å­—æ®µï¼Œå…¶å†…å®¹æ˜¯ä¸€æ®µè¯¦ç»†çš„æ–‡æœ¬æŒ‡ä»¤ã€‚
é‡è¦æç¤ºï¼šæ‰€æœ‰ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹éƒ½å¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚"""
        
        response = self.ai_service.call_ai_model(prompt, expect_json=True)
        brief = response.get("creative_brief")
        if not brief:
            raise ValueError("AIæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„åˆ›ä½œæŒ‡ä»¤")
        
        self.state.data['creativeBrief'] = brief
        
        # æå–é¡¹ç›®åç§°
        project_prompt = f"""ä»ä»¥ä¸‹åˆ›ä½œæŒ‡ä»¤ä¸­ï¼Œæå–ä¸€ä¸ªç®€çŸ­çš„æ ¸å¿ƒé¡¹ç›®åç§°æˆ–ä¸»é¢˜ï¼ˆä¾‹å¦‚ï¼Œ"é•¿æ²™ç†å·¥å¤§å­¦ç¾½æ¯›çƒæ¯”èµ›"æˆ–"1å·ä½å®…æ¥¼ç»“æ„è®¾è®¡"ï¼‰ï¼Œç”¨äºä¼˜åŒ–åç»­çš„çŸ¥è¯†åº“æ£€ç´¢ã€‚
è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåªåŒ…å«ä¸€ä¸ª 'project_name' å­—æ®µã€‚
é‡è¦æç¤ºï¼šé¡¹ç›®åç§°å¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚

åˆ›ä½œæŒ‡ä»¤ï¼š{brief}"""
        
        name_response = self.ai_service.call_ai_model(project_prompt, expect_json=True)
        project_name = name_response.get("project_name", "")
        self.state.data['projectName'] = project_name
        
        self.state.data['status'] = 'brief_prepared'
        self.state.save()
        
        logger.info(f"åˆ›ä½œæŒ‡ä»¤å·²ç”Ÿæˆï¼Œé¡¹ç›®åç§°: {project_name}")
    
    def _generate_initial_outline(self):
        """ç”Ÿæˆåˆå§‹å¤§çº²"""
        self.state.update_status("outline_generation", "æ­£åœ¨ç”Ÿæˆæ–‡æ¡£å¤§çº²...", 15)
        
        prompt = f"""æ ¹æ®ä»¥ä¸‹åˆ›ä½œæŒ‡ä»¤ï¼Œä¸ºä¸€ç¯‡é•¿æ–‡æ¡£ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„JSONæ ¼å¼å¤§çº²ã€‚
JSONçš„æ ¹èŠ‚ç‚¹åº”è¯¥æœ‰ä¸€ä¸ªåä¸º 'chapters' çš„åˆ—è¡¨ã€‚
åˆ—è¡¨ä¸­çš„æ¯ä¸ªå¯¹è±¡éƒ½åº”åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªå­—æ®µï¼š
1. 'chapterId' (å­—ç¬¦ä¸², ä¾‹å¦‚ "ch_01")
2. 'title' (å­—ç¬¦ä¸², ç« èŠ‚çš„æ ‡é¢˜)
3. 'key_points' (å­—ç¬¦ä¸²åˆ—è¡¨, è¿™ä¸€ç« çš„å…³é”®è®ºç‚¹)

é‡è¦æç¤ºï¼šæ‰€æœ‰ç”Ÿæˆçš„æ ‡é¢˜å’Œæ–‡æœ¬å†…å®¹éƒ½å¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚

æŒ‡ä»¤ï¼š{self.state.data['creativeBrief']}"""
        
        response = self.ai_service.call_ai_model(prompt, expect_json=True)
        chapters = response.get('chapters')
        if chapters is None:
            raise ValueError("AIæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„å¤§çº²")
        
        self.state.data['outline'] = {
            "metadata": {"refinementCycles": 0},
            "chapters": chapters
        }
        self.state.data['status'] = 'outline_generated'
        self.state.save()
        
        logger.info(f"å¤§çº²å·²ç”Ÿæˆï¼ŒåŒ…å« {len(chapters)} ä¸ªç« èŠ‚")
    
    def _refine_outline(self):
        """ç²¾ç‚¼å¤§çº²"""
        self.state.update_status("outline_refinement", "å¼€å§‹å¤§çº²ç²¾ç‚¼...", 25)
        
        project_name = self.state.data.get('projectName', '')
        
        for i in range(self.config.MAX_REFINEMENT_CYCLES):
            self.state.update_status("outline_refinement", f"ç¬¬ {i + 1} è½®å¤§çº²ç²¾ç‚¼...", 25 + i * 5)
            
            current_outline = json.dumps(self.state.data['outline']['chapters'], ensure_ascii=False)
            
            # AIè¯„å®¡å¤§çº²
            critique_prompt = f"""ä½ æ˜¯ä¸€ä½è¿½æ±‚å®Œç¾çš„èµ„æ·±ç¼–è¾‘ã€‚è¯·è¯„å®¡ä»¥ä¸‹å¤§çº²ã€‚
å³ä½¿å®ƒçœ‹èµ·æ¥é€»è¾‘å®Œæ•´ï¼Œä¹Ÿè¯·ä½ ä¸»åŠ¨æ€è€ƒï¼šå“ªäº›ç« èŠ‚å¯ä»¥é€šè¿‡è¡¥å……å¤–éƒ¨çš„ã€æ›´å…·ä½“çš„æ•°æ®ã€æ¡ˆä¾‹æˆ–ç»†èŠ‚æ¥å˜å¾—æ›´å…·æ·±åº¦å’Œè¯´æœåŠ›ï¼Ÿ

è¯·ä»¥JSONæ ¼å¼è¿”å›ä½ çš„åˆ†æã€‚JSONçš„æ ¹èŠ‚ç‚¹åº”åŒ…å«ä¸€ä¸ªåä¸º 'gaps_identified' çš„åˆ—è¡¨ã€‚
åˆ—è¡¨ä¸­çš„æ¯ä¸ªå¯¹è±¡éƒ½åº”ä»£è¡¨ä¸€ä¸ªéœ€è¦è¡¥å……ä¿¡æ¯çš„ç« èŠ‚ï¼Œå¹¶åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
1. 'chapterId' (å­—ç¬¦ä¸², å¯¹åº”åŸå¤§çº²ä¸­çš„ç« èŠ‚ID)
2. 'title' (å­—ç¬¦ä¸², å¯¹åº”åŸå¤§çº²ä¸­çš„ç« èŠ‚æ ‡é¢˜)
3. 'query_keywords' (å­—ç¬¦ä¸²åˆ—è¡¨, ç”¨äºæ£€ç´¢å¤–éƒ¨çŸ¥è¯†çš„æ¨èå…³é”®è¯)

å¦‚æœè¿™ä¸ªå¤§çº²ç¡®å®å®Œç¾æ— ç¼ºï¼Œæ‰è¿”å›ä¸€ä¸ªç©ºçš„ 'gaps_identified' åˆ—è¡¨ã€‚
é‡è¦æç¤ºï¼šæ‰€æœ‰ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹éƒ½å¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚

å¤§çº²ï¼š{current_outline}"""
            
            critique_response = self.ai_service.call_ai_model(critique_prompt, expect_json=True)
            gaps = critique_response.get('gaps_identified', [])
            
            if not gaps:
                logger.info("å¤§çº²ç²¾ç‚¼å®Œæˆï¼ŒAIè®¤ä¸ºå¤§çº²å·²è¶³å¤Ÿå®Œå–„")
                break
            
            # æ£€ç´¢å¤–éƒ¨çŸ¥è¯†
            all_knowledge = []
            all_gap_titles = []
            
            for gap_info in gaps:
                gap_title = gap_info.get('title', '')
                if gap_title:
                    all_gap_titles.append(gap_title)
                
                query_keywords = gap_info.get('query_keywords', [])
                for keyword in query_keywords:
                    scoped_query = f"{project_name} {keyword}".strip()
                    knowledge_pieces = self.ai_service.search_vectordata(scoped_query)
                    all_knowledge.extend(knowledge_pieces)
            
            if not all_knowledge:
                logger.info("æœªæ£€ç´¢åˆ°æœ‰æ•ˆçŸ¥è¯†ï¼Œè·³è¿‡æœ¬è½®ç²¾ç‚¼")
                continue
            
            # æ•´åˆçŸ¥è¯†åˆ°å¤§çº²
            knowledge_str = "\n\n---\n\n".join(all_knowledge)
            integrate_prompt = f"""è¯·å‚è€ƒä»¥ä¸‹èƒŒæ™¯èµ„æ–™ï¼Œæ‰©å……å’Œå®Œå–„è¿™ä»½å¤§çº²ï¼Œç‰¹åˆ«æ˜¯å…³äº'{','.join(all_gap_titles)}'çš„è¿™äº›ç« èŠ‚ã€‚
è¯·è¿”å›å®Œæ•´çš„ã€æ›´æ–°åçš„JSONæ ¼å¼å¤§çº²ã€‚
è¿”å›çš„JSONç»“æ„åº”ä¸åŸå¤§çº²ä¸€è‡´ï¼ˆä¸€ä¸ªåŒ…å« 'chapters' åˆ—è¡¨çš„æ ¹å¯¹è±¡ï¼‰ã€‚
é‡è¦æç¤ºï¼šæ‰€æœ‰ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹éƒ½å¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚

èƒŒæ™¯èµ„æ–™ï¼š{knowledge_str}

åŸå¤§çº²ï¼š{current_outline}"""
            
            updated_response = self.ai_service.call_ai_model(integrate_prompt, expect_json=True)
            updated_chapters = updated_response.get('chapters', self.state.data['outline']['chapters'])
            
            self.state.data['outline']['chapters'] = updated_chapters
            self.state.data['outline']['metadata']['refinementCycles'] = i + 1
            self.state.save()
        
        self.state.data['status'] = 'outline_finalized'
        self.state.update_status("outline_finalized", "å¤§çº²å·²æœ€ç»ˆç¡®å®š", 40)
    
    def _generate_chapters(self):
        """ç”Ÿæˆç« èŠ‚å†…å®¹"""
        chapters = self.state.data['outline']['chapters']
        project_name = self.state.data.get('projectName', '')
        total_chapters = len(chapters)
        
        if total_chapters == 0:
            logger.warning("å¤§çº²ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆç« èŠ‚å†…å®¹")
            self.state.data['status'] = 'chapters_generated'
            self.state.save()
            return
        
        for i, chapter in enumerate(chapters):
            progress = 40 + int((i / total_chapters) * 40)
            chapter_title = chapter.get('title', '')
            
            self.state.update_status("content_generation", 
                                   f"æ­£åœ¨ç”Ÿæˆç¬¬ {i + 1}/{total_chapters} ç« : '{chapter_title}'...", 
                                   progress)
            
            # æ£€ç´¢ç« èŠ‚ç›¸å…³çŸ¥è¯†
            scoped_query = f"{project_name} {chapter_title}".strip()
            knowledge_pieces = self.ai_service.search_vectordata(scoped_query)
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context = f"è¿™æ˜¯å…¨æ–‡å¤§çº²ï¼š{json.dumps(self.state.data['outline']['chapters'], ensure_ascii=False)}\n"
            if i > 0:
                context += f"å‰ä¸€ç« æ˜¯å…³äº '{chapters[i - 1].get('title', '')}' çš„ã€‚\n"
            
            if knowledge_pieces:
                knowledge_str = "\n\n---\n\n".join(knowledge_pieces)
                context += f"\nåœ¨æ’°å†™æœ¬ç« æ—¶ï¼Œè¯·é‡ç‚¹å‚è€ƒä»¥ä¸‹èƒŒæ™¯èµ„æ–™ä»¥ç¡®ä¿å†…å®¹çš„å‡†ç¡®æ€§å’Œæ·±åº¦ï¼š\n{knowledge_str}\n"
            
            # ç”Ÿæˆç« èŠ‚å†…å®¹
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œæ’°å†™ '{chapter_title}' è¿™ä¸€ç« çš„è¯¦ç»†å†…å®¹ã€‚
è¯·ä¸“æ³¨äºé˜è¿°è¿™äº›è¦ç‚¹ï¼š{', '.join(chapter.get('key_points', []))}ã€‚
é‡è¦æç¤ºï¼šæ‰€æœ‰ä½ æ’°å†™çš„å†…å®¹éƒ½å¿…é¡»æ˜¯ä¸­æ–‡ã€‚"""
            
            response = self.ai_service.call_ai_model(prompt, context=context)
            chapter['content'] = response.get('text', '')
            self.state.save()
        
        self.state.data['status'] = 'chapters_generated'
        self.state.save()
        
        logger.info(f"æ‰€æœ‰ {total_chapters} ä¸ªç« èŠ‚å†…å®¹å·²ç”Ÿæˆ")
    
    def _assemble_final_document(self):
        """ç»„è£…æœ€ç»ˆæ–‡æ¡£"""
        self.state.update_status("assembling", "æ­£åœ¨ç»„è£…æœ€ç»ˆæ–‡æ¡£...", 85)
        
        chapters = self.state.data['outline']['chapters']
        
        # ç”Ÿæˆå¼•è¨€
        intro_prompt = "æ ¹æ®ä»¥ä¸‹å®Œæ•´å¤§çº²ï¼Œä¸ºè¿™ç¯‡æ–‡æ¡£æ’°å†™ä¸€æ®µç²¾å½©çš„å¼•è¨€ã€‚é‡è¦æç¤ºï¼šå¼•è¨€å¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚"
        intro_context = json.dumps(chapters, ensure_ascii=False)
        intro_response = self.ai_service.call_ai_model(intro_prompt, intro_context)
        
        # ç”Ÿæˆç»“è®º
        conclusion_prompt = "æ ¹æ®ä»¥ä¸‹å®Œæ•´å¤§çº²å’Œæ‰€æœ‰ç« èŠ‚å†…å®¹ï¼Œä¸ºè¿™ç¯‡æ–‡æ¡£æ’°å†™ä¸€æ®µæ€»ç»“æ€§çš„ç»“è®ºã€‚é‡è¦æç¤ºï¼šç»“è®ºå¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚"
        conclusion_response = self.ai_service.call_ai_model(conclusion_prompt, intro_context)
        
        # ç»„è£…å®Œæ•´æ–‡æ¡£
        full_text_parts = [intro_response.get('text', '')]
        
        for chapter in chapters:
            full_text_parts.append(f"\n\n## {chapter.get('title', '')}\n\n")
            full_text_parts.append(chapter.get('content', ''))
        
        full_text_parts.append(f"\n\n## ç»“è®º\n\n")
        full_text_parts.append(conclusion_response.get('text', ''))
        
        self.state.data['finalDocument'] = "".join(full_text_parts)
        
        # åˆ›å»ºå¹¶ä¸Šä¼ DOCXæ–‡ä»¶
        try:
            self.state.update_status("docx_creation", "æ­£åœ¨åˆ›å»ºDOCXæ–‡æ¡£...", 90)
            
            project_name = self.state.data.get('projectName', 'ç”Ÿæˆæ–‡æ¡£')
            docx_path = self.doc_service.create_docx(
                self.state.data['finalDocument'], 
                project_name, 
                self.task_id
            )
            
            self.state.data['docxLocalPath'] = docx_path
            
            # å°è¯•ä¸Šä¼ åˆ°äº‘å­˜å‚¨
            docx_filename = f"task_{self.task_id}.docx"
            public_url = self.doc_service.upload_to_minio(docx_path, docx_filename)
            if public_url:
                self.state.data['docxPublicUrl'] = public_url
            
        except Exception as e:
            logger.warning(f"åˆ›å»ºæˆ–ä¸Šä¼ DOCXå¤±è´¥: {e}")
            self.state.log_error("docx_handling", str(e))
        
        self.state.update_status("completed", "æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼", 100)
        logger.info(f"ä»»åŠ¡ {self.task_id} å®Œæˆ")

class AdvancedLongDocumentGeneratorTool(Tool):
    """é«˜çº§é•¿æ–‡æ¡£ç”Ÿæˆå·¥å…·"""
    
    def __init__(self):
        super().__init__(
            name="advanced_long_document_generator",
            description="ğŸš€ é«˜çº§é•¿æ–‡æ¡£ç”Ÿæˆå·¥å…· - åŸºäºAIçš„ä¸“ä¸šé•¿ç¯‡æ–‡æ¡£æ™ºèƒ½ç”Ÿæˆå™¨ï¼\n\n"
                       "âœ¨ **æ ¸å¿ƒåŠŸèƒ½ï¼š**\n"
                       "- ğŸ§  AIé©±åŠ¨çš„åˆ›ä½œæŒ‡ä»¤åˆ†æ\n"
                       "- ğŸ“‹ æ™ºèƒ½å¤§çº²ç”Ÿæˆä¸ç²¾ç‚¼\n"
                       "- ğŸ” å‘é‡çŸ¥è¯†åº“æ£€ç´¢å¢å¼º\n"
                       "- âœï¸ é€ç« èŠ‚å†…å®¹ç”Ÿæˆ\n"
                       "- ğŸ“„ ä¸“ä¸šDOCXæ–‡æ¡£è¾“å‡º\n"
                       "- â˜ï¸ äº‘å­˜å‚¨è‡ªåŠ¨ä¸Šä¼ \n\n"
                       "ğŸ¯ **é€‚ç”¨åœºæ™¯ï¼š**\n"
                       "- æŠ€æœ¯æŠ¥å‘Šã€ç ”ç©¶æŠ¥å‘Šã€é¡¹ç›®æŠ¥å‘Š\n"
                       "- æ–½å·¥æ–¹æ¡ˆã€è®¾è®¡æ–¹æ¡ˆã€å®æ–½æ–¹æ¡ˆ\n"
                       "- å­¦æœ¯è®ºæ–‡ã€è°ƒç ”åˆ†æã€å¯è¡Œæ€§ç ”ç©¶\n"
                       "- äº§å“æ–‡æ¡£ã€æŠ€æœ¯è§„èŒƒã€æ“ä½œæ‰‹å†Œ\n\n"
                       "ğŸ“Š **æ™ºèƒ½ç‰¹æ€§ï¼š**\n"
                       "- å¤šè½®å¤§çº²ç²¾ç‚¼ä¼˜åŒ–\n"
                       "- å¤–éƒ¨çŸ¥è¯†åº“æ™ºèƒ½æ£€ç´¢\n"
                       "- ä»»åŠ¡çŠ¶æ€å®æ—¶è·Ÿè¸ª\n"
                       "- ä¸“ä¸šæ ¼å¼æ–‡æ¡£è¾“å‡º\n\n"
                       "ğŸ”§ **ä½¿ç”¨æ–¹æ³•ï¼š**\n"
                       "generate_document(request='ç”Ÿæˆéœ€æ±‚æè¿°', chathistory='å¯é€‰çš„èŠå¤©å†å²')"
        )
    
    def execute(self, action: str = "generate", request: str = "", chathistory: str = "", **kwargs) -> str:
        """
        æ‰§è¡Œé«˜çº§é•¿æ–‡æ¡£ç”Ÿæˆ
        
        Args:
            action: æ“ä½œç±»å‹ï¼Œé»˜è®¤ä¸º"generate"
            request: ç”Ÿæˆéœ€æ±‚æè¿°
            chathistory: å¯é€‰çš„èŠå¤©å†å²ä¸Šä¸‹æ–‡
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            ç”Ÿæˆç»“æœçš„JSONå­—ç¬¦ä¸²
        """
        try:
            if action == "generate":
                if not request:
                    return json.dumps({
                        "success": False,
                        "error": "è¯·æä¾›ç”Ÿæˆéœ€æ±‚æè¿°ï¼ˆrequestå‚æ•°ï¼‰"
                    }, ensure_ascii=False)
                
                # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
                generator = AdvancedLongDocumentGenerator()
                
                # æ‰§è¡Œç”Ÿæˆ
                result = generator.generate_document(request, chathistory)
                
                return json.dumps(result, ensure_ascii=False, indent=2)
            
            elif action == "status":
                # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
                task_id = kwargs.get("task_id")
                if not task_id:
                    return json.dumps({
                        "success": False,
                        "error": "è¯·æä¾›ä»»åŠ¡IDï¼ˆtask_idå‚æ•°ï¼‰"
                    }, ensure_ascii=False)
                
                config = AdvancedLongDocumentConfig()
                state = TaskState(task_id, config)
                
                if state.load():
                    return json.dumps({
                        "success": True,
                        "task_id": task_id,
                        "status": state.data.get("status"),
                        "progress": state.data.get("progressPercentage"),
                        "message": state.data.get("currentStatusMessage"),
                        "docx_url": state.data.get("docxPublicUrl"),
                        "docx_path": state.data.get("docxLocalPath")
                    }, ensure_ascii=False)
                else:
                    return json.dumps({
                        "success": False,
                        "error": f"æœªæ‰¾åˆ°ä»»åŠ¡: {task_id}"
                    }, ensure_ascii=False)
            
            else:
                return json.dumps({
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„æ“ä½œ: {action}ã€‚æ”¯æŒçš„æ“ä½œ: generate, status"
                }, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"é«˜çº§é•¿æ–‡æ¡£ç”Ÿæˆå·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            return json.dumps({
                "success": False,
                "error": f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            }, ensure_ascii=False)

# åˆ›å»ºå·¥å…·å®ä¾‹
def create_advanced_long_document_generator_tool() -> AdvancedLongDocumentGeneratorTool:
    """åˆ›å»ºé«˜çº§é•¿æ–‡æ¡£ç”Ÿæˆå·¥å…·å®ä¾‹"""
    return AdvancedLongDocumentGeneratorTool() 