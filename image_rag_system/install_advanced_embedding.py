#!/usr/bin/env python3
"""
é«˜è´¨é‡åµŒå…¥æ¨¡å‹å®‰è£…è„šæœ¬
å®‰è£… BGE-M3 (å¤šåŠŸèƒ½ã€å¤šè¯­è¨€ã€è½»é‡çº§)
"""

import subprocess
import sys
import torch
import time

def run_command(command, description):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¿›åº¦"""
    print(f"\nğŸ”§ {description}...")
    try:
        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)
        print(f"âœ… {description} å®Œæˆ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {description} å¤±è´¥:")
        print(f"é”™è¯¯: {e.stderr}")
        return False

def check_gpu():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    print("\nğŸ” æ£€æŸ¥ç³»ç»Ÿé…ç½®...")
    
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        
        print(f"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
        print(f"   ä¸»GPU: {gpu_name}")
        print(f"   æ˜¾å­˜: {gpu_memory:.1f} GB")
        
        if gpu_memory < 2:
            print("âš ï¸  è­¦å‘Š: BGE-M3 æ¨èè‡³å°‘2GBæ˜¾å­˜")
            print("   ä¸è¿‡CPUæ¨¡å¼ä¹Ÿå¯ä»¥è¿è¡Œ")
        else:
            print("âœ… æ˜¾å­˜å……è¶³ï¼Œå¯ä»¥è¿è¡ŒBGE-M3")
        return True
    else:
        print("âŒ æœªæ£€æµ‹åˆ°CUDA GPU")
        print("   æ³¨æ„: é«˜è´¨é‡æ¨¡å‹éœ€è¦GPUæ”¯æŒ")
        return False

def install_dependencies():
    """å®‰è£…ä¾èµ–åŒ…"""
    print("\nğŸ“¦ å®‰è£…ä¾èµ–åŒ…...")
    
    # æ ¸å¿ƒä¾èµ–
    packages = [
        "transformers>=4.35.0",
        "sentence-transformers>=2.2.0", 
        "FlagEmbedding>=1.2.0",
        "torch>=2.0.0"
    ]
    
    # å¯é€‰ä½†æ¨èçš„åŒ…
    optional_packages = [
        "xformers",           # å†…å­˜ä¼˜åŒ–
    ]
    
    # å®‰è£…æ ¸å¿ƒä¾èµ–
    for package in packages:
        if not run_command(f"pip install {package}", f"å®‰è£… {package}"):
            return False
    
    # å°è¯•å®‰è£…å¯é€‰ä¾èµ–
    for package in optional_packages:
        print(f"\nğŸ”§ å°è¯•å®‰è£… {package} (å¯é€‰ä¼˜åŒ–åŒ…)...")
        try:
            subprocess.run(f"pip install {package}", shell=True, check=True, capture_output=True)
            print(f"âœ… {package} å®‰è£…æˆåŠŸ")
        except:
            print(f"âš ï¸  {package} å®‰è£…å¤±è´¥ï¼Œè·³è¿‡ (ä¸å½±å“åŸºæœ¬åŠŸèƒ½)")
    
    return True

def download_model():
    """é¢„ä¸‹è½½æ¨¡å‹"""
    print("\nğŸ“¥ é¢„ä¸‹è½½æ¨¡å‹...")
    
    download_script = '''
import torch
from FlagEmbedding import BGEM3FlagModel

print("æ­£åœ¨ä¸‹è½½ BGE-M3 æ¨¡å‹...")
try:
    model = BGEM3FlagModel(
        'BAAI/bge-m3',
        use_fp16=False,  # CPUæ¨¡å¼ä¸‹ä¸ä½¿ç”¨FP16
        device="cpu"     # å…ˆåœ¨CPUä¸ŠåŠ è½½ï¼Œé¿å…æ˜¾å­˜é—®é¢˜
    )
    print("âœ… BGE-M3æ¨¡å‹ä¸‹è½½å®Œæˆ")
    
    # æµ‹è¯•ç¼–ç 
    test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
    output = model.encode(test_text, return_dense=True, return_sparse=False, return_colbert_vecs=False)
    embeddings = output['dense_vecs']
    print(f"âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸï¼ŒåµŒå…¥ç»´åº¦: {embeddings.shape}")
    
except Exception as e:
    print(f"âŒ BGE-M3æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
    exit(1)
'''
    
    try:
        with open("temp_download_model.py", "w", encoding="utf-8") as f:
            f.write(download_script)
        
        result = subprocess.run([sys.executable, "temp_download_model.py"], 
                              capture_output=True, text=True, timeout=600)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import os
        if os.path.exists("temp_download_model.py"):
            os.remove("temp_download_model.py")
            
        if result.returncode == 0:
            print("âœ… æ¨¡å‹é¢„ä¸‹è½½æˆåŠŸ")
            return True
        else:
            print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print("âŒ æ¨¡å‹ä¸‹è½½è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¸‹è½½å¼‚å¸¸: {e}")
        return False

def test_embedding_service():
    """æµ‹è¯•åµŒå…¥æœåŠ¡"""
    print("\nğŸ§ª æµ‹è¯•åµŒå…¥æœåŠ¡...")
    
    test_script = '''
import sys
import os
sys.path.insert(0, os.getcwd())

try:
    from app.services.embedding_service_advanced import AdvancedEmbeddingService
    
    print("åˆå§‹åŒ–é«˜è´¨é‡åµŒå…¥æœåŠ¡...")
    service = AdvancedEmbeddingService()
    
    # æµ‹è¯•æ–‡æœ¬åµŒå…¥
    text = "æµ‹è¯•ä¸­æ–‡æ–‡æœ¬åµŒå…¥æ•ˆæœ"
    text_embedding = service.encode_text(text)
    print(f"âœ… æ–‡æœ¬åµŒå…¥æˆåŠŸï¼Œç»´åº¦: {text_embedding.shape}")
    
    # æµ‹è¯•å›¾ç‰‡åµŒå…¥ï¼ˆå¦‚æœCLIPå¯ç”¨ï¼‰
    from PIL import Image
    import numpy as np
    
    # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
    test_image = Image.fromarray(np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8))
    image_embedding = service.encode_image(test_image)
    print(f"âœ… å›¾ç‰‡åµŒå…¥æˆåŠŸï¼Œç»´åº¦: {image_embedding.shape}")
    
    # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
    similarity = service.compute_similarity(text_embedding, image_embedding)
    print(f"âœ… ç›¸ä¼¼åº¦è®¡ç®—æˆåŠŸ: {similarity:.4f}")
    
    # æ¸…ç†èµ„æº
    service.cleanup()
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
    
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    exit(1)
'''
    
    try:
        with open("temp_test_service.py", "w", encoding="utf-8") as f:
            f.write(test_script)
        
        result = subprocess.run([sys.executable, "temp_test_service.py"], 
                              capture_output=True, text=True, timeout=300)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import os
        if os.path.exists("temp_test_service.py"):
            os.remove("temp_test_service.py")
            
        if result.returncode == 0:
            print("âœ… åµŒå…¥æœåŠ¡æµ‹è¯•æˆåŠŸ")
            print(result.stdout)
            return True
        else:
            print(f"âŒ åµŒå…¥æœåŠ¡æµ‹è¯•å¤±è´¥:")
            print(result.stderr)
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def main():
    """ä¸»å®‰è£…æµç¨‹"""
    print("ğŸš€ BGE-M3åµŒå…¥æ¨¡å‹å®‰è£…è„šæœ¬")
    print("="*50)
    print("æ¨¡å‹: BAAI/bge-m3")
    print("ç‰¹æ€§: å¤šåŠŸèƒ½(Dense+Sparse+ColBERT)ã€å¤šè¯­è¨€(100+)ã€é•¿æ–‡æœ¬(8192)")
    print("æ˜¾å­˜éœ€æ±‚: ~2GB (vs Qwen2çš„16GB+)")
    print("="*50)
    
    # 1. æ£€æŸ¥GPU
    gpu_ok = check_gpu()
    if not gpu_ok:
        response = input("\næ˜¯å¦ç»§ç»­å®‰è£…? (y/N): ")
        if response.lower() != 'y':
            print("å®‰è£…å–æ¶ˆ")
            return
    
    # 2. å®‰è£…ä¾èµ–
    if not install_dependencies():
        print("âŒ ä¾èµ–å®‰è£…å¤±è´¥")
        return
    
    # 3. ä¸‹è½½æ¨¡å‹
    if not download_model():
        print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
        return
    
    # 4. æµ‹è¯•æœåŠ¡
    if not test_embedding_service():
        print("âŒ æœåŠ¡æµ‹è¯•å¤±è´¥")
        return
    
    print("\nğŸ‰ BGE-M3åµŒå…¥æ¨¡å‹å®‰è£…å®Œæˆ!")
    print("\nğŸ“‹ å®‰è£…æ€»ç»“:")
    print("  âœ… ä¾èµ–åŒ…å·²å®‰è£…")
    print("  âœ… BGE-M3 æ¨¡å‹å·²ä¸‹è½½")
    print("  âœ… åµŒå…¥æœåŠ¡æµ‹è¯•é€šè¿‡")
    print("\nğŸš€ ä¸‹ä¸€æ­¥:")
    print("  1. è¿è¡Œ: python app_complete.py")
    print("  2. è®¿é—®: http://localhost:8080")
    print("  3. æŸ¥çœ‹: ç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨BGE-M3æ¨¡å‹")

if __name__ == "__main__":
    main() 